《机器学习实战》
-----------

2. KNN  计算距离分类

 kNN中文又称为k-近邻算法，其基本思想是通过计算输入样本点和训练集样本点之前的这两个向量之前的距离，距离越近的话，说明其特征

 越靠近，通过取出其k个距离最近的样本点，然后计算这k个样本点中类别占比最大的类比以此来预测输入样本点(被测样本点)的类别


kNN的优势
kNN是ML里最简单，最基本的算法。
kNN不会受到差别特别大的样本中的特征元素的影响(对异常值不敏感)。因为采用了归一化技术
kNN的精度高
kNN的劣势
kNN算法时间复杂度较高，需要计算被测样本点和训练集中所有样本点的距离


3. Decision Tree: 按照计算的熵分类

4. Naive Bayes: 计算条件概率，选择高概率的决策
5. Logistic Regression/逻辑回归：更具梯度上升的方法，拟合数据，分类数据
6. SVM:二值分类器：求解一个二次优化问题，来最大化分类间隔，产生一个二值决策结果 (SMO/Sequential Minimal Optimization 序列最小优化)
8. 回归：预测数值数据， 包括：线性回归（最小二乘法拟合参数），局部加权线性回归,岭回归
9. 树回归：CART/分类树回归，建立二叉树然后使用回归分类 classifciation and regression tree


